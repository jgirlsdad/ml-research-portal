{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pymongo\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0  gene_0    gene_1    gene_2    gene_3     gene_4  gene_5  \\\n",
      "0   sample_0     0.0  2.017209  3.265527  5.478487  10.431999     0.0   \n",
      "1   sample_1     0.0  0.592732  1.588421  7.586157   9.623011     0.0   \n",
      "2   sample_2     0.0  3.511759  4.327199  6.881787   9.870730     0.0   \n",
      "3   sample_3     0.0  3.663618  4.507649  6.659068  10.196184     0.0   \n",
      "4   sample_4     0.0  2.655741  2.821547  6.539454   9.738265     0.0   \n",
      "\n",
      "     gene_6    gene_7  gene_8  ...  gene_20521  gene_20522  gene_20523  \\\n",
      "0  7.175175  0.591871     0.0  ...    4.926711    8.210257    9.723516   \n",
      "1  6.816049  0.000000     0.0  ...    4.593372    7.323865    9.740931   \n",
      "2  6.972130  0.452595     0.0  ...    5.125213    8.127123   10.908640   \n",
      "3  7.843375  0.434882     0.0  ...    6.076566    8.792959   10.141520   \n",
      "4  6.566967  0.360982     0.0  ...    5.996032    8.891425   10.373790   \n",
      "\n",
      "   gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
      "0    7.220030    9.119813   12.003135    9.650743    8.921326    5.286759   \n",
      "1    6.256586    8.381612   12.674552   10.517059    9.397854    2.094168   \n",
      "2    5.401607    9.911597    9.045255    9.788359   10.090470    1.683023   \n",
      "3    8.942805    9.601208   11.392682    9.694814    9.684365    3.292001   \n",
      "4    7.181162    9.846910   11.922439    9.217749    9.461191    5.110372   \n",
      "\n",
      "   gene_20530  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "\n",
      "[5 rows x 20532 columns]\n"
     ]
    }
   ],
   "source": [
    "genes = pd.read_csv(\"data/gene-data.csv\")\n",
    "print (genes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gene_0', 'gene_1', 'gene_2', 'gene_3', 'gene_4', 'gene_5', 'gene_6',\n",
      "       'gene_7', 'gene_8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "genes_labels = pd.read_csv(\"data/gene-labels.csv\")\n",
    "#print (genes_labels.head())\n",
    "print (genes.columns[1:10])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "label_encoder.fit(genes_labels[\"Class\"])\n",
    "classes = label_encoder.classes_\n",
    "\n",
    "\n",
    "###  Logist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRAD' 'LUAD' 'BRCA' 'KIRC' 'COAD']\n"
     ]
    }
   ],
   "source": [
    "print (genes_labels['Class'].unique())\n",
    "y = label_encoder.transform(genes_labels['Class'])\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = 5\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://jgirlsdad:444jayla@cluster0-dgjk9.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "mydb = client.finalproject\n",
    "mycol = mydb[\"genes9\"]\n",
    "\n",
    "record = {}\n",
    "record['class'] = \"info\"\n",
    "record['info'] = f\"Use {estimators} estimators and 100 indendent prediction points \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  Random Forest\n",
    "\n",
    "def randomForest(XX,yy):\n",
    "    ninst = len(yy)\n",
    "  \n",
    "    y=yy[0:ninst-101]\n",
    "    X=XX[0:ninst-101]\n",
    "    X_exp = XX[ninst-100:]\n",
    "    y_exp = yy[ninst-100:]\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=estimators)\n",
    "    parameters = { \n",
    "        'max_features':[1,2,3,4,5],\n",
    "        'n_estimators':[5,10,50,100],\n",
    "        'min_samples_leaf': [1,5,10,50,100]\n",
    "    }\n",
    "\n",
    "    rfg = GridSearchCV(rf, parameters)\n",
    "    rfg.fit(X_train, y_train)\n",
    "    print (\"Best\")\n",
    "    print (rfg.best_estimator_)\n",
    "    print (rfg.best_score_)\n",
    "    print (rfg.best_params_)\n",
    "    print (rfg.best_index_)\n",
    "    train_score = rfg.score(X_train, y_train)\n",
    "    test_score = rfg.score(X_test, y_test)\n",
    "##    importances = rfg.feature_importances_\n",
    "    #\n",
    " #   y_pred = rfg.predict(XX)\n",
    "    y_pred = rfg.predict(X_exp)\n",
    "##    importances = rfg.feature_importances_\n",
    "    success=0\n",
    "    fail=0 \n",
    "    s = {}\n",
    "    f= {}\n",
    "    for nn in range(0,len(y_pred)):\n",
    "   #     if (y_pred[nn] == yy[nn]):\n",
    "        if (y_pred[nn] == y_exp[nn]):\n",
    "            success+=1\n",
    "            if classes[y_pred[nn]] in s:\n",
    "                s[classes[y_pred[nn]]] +=1\n",
    "            else:\n",
    "                s[classes[y_pred[nn]]] = 1\n",
    "        else:\n",
    "            fail+=1\n",
    "            if classes[y_pred[nn]] in f:\n",
    "                f[classes[y_pred[nn]]] +=1\n",
    "            else:\n",
    "                f[classes[y_pred[nn]]] = 1\n",
    "    \n",
    "    return train_score,test_score,success,fail,s,f\n",
    "#    return train_score,test_score,importances,success,fail,s,f\n",
    "\n",
    "# xx = mycol.insert_one(record)\n",
    "\n",
    "y = label_encoder.transform(genes_labels['Class'])\n",
    "y = y.reshape(-1,1)\n",
    "nstep=5\n",
    "hact = {}\n",
    "record = {}\n",
    "record['class'] = \"summary\"\n",
    "for val in genes_labels['Class'].values:\n",
    "    if val in hact:\n",
    "        hact[val]+=1\n",
    "    else:\n",
    "        hact[val] = 1\n",
    "\n",
    "for val in hact:\n",
    "    record[val] = hact[val]\n",
    "    \n",
    "\n",
    "nxx = mycol.insert_one(record)\n",
    "nfeatures = len(genes.columns)\n",
    "nfeatures=200\n",
    "\n",
    "for nn in range(1,nfeatures,nstep):\n",
    "  nend = nn+nstep\n",
    "  if (nend > nfeatures):\n",
    "        nend=nfeatures\n",
    "  X = genes.ix[:,nn:nend].values.reshape(-1,nstep)\n",
    "  y_labs = genes.columns[nn:nend]\n",
    "  (train_score,test_score,success,fail,hist_suc,hist_fail) = randomForest(X,y)\n",
    "#  (train_score,test_score,important,success,fail,hist_suc,hist_fail) = randomForest(X,y)\n",
    "#  print (nn,nn+nstep,train_score,test_score,important,success,fail,hist_suc,hist_fail,y_labs)\n",
    "  print (nn,nend,train_score,test_score,success,fail)\n",
    "  record = {}  \n",
    "  record['class'] = \"analysis\"\n",
    "  record['iteration'] = nn\n",
    "##  for nn in range(0,len(y_labs)):\n",
    "##      record[y_labs[nn]] = important[nn] \n",
    "                  \n",
    "  record['train_score'] = train_score\n",
    "  record['test_score'] = test_score\n",
    "  record['predict_success'] = success\n",
    "  record['predict_fail'] = fail\n",
    "  s = {}  \n",
    "  f={}\n",
    "  sp = {}\n",
    "  for nn in classes:\n",
    "      if nn in hist_suc:\n",
    "        ss = hist_suc[nn]\n",
    "      else:\n",
    "        ss=0\n",
    "        \n",
    "      if nn in hist_fail:\n",
    "        ff = hist_fail[nn]\n",
    "      else:\n",
    "        ff=0\n",
    "        \n",
    "      s[nn] = ss\n",
    "      if (ss+ff) > 0:\n",
    "        sp[nn] = ss/ (ss+ff)    \n",
    "      else:\n",
    "        sp[nn] = 0\n",
    "        \n",
    "      f[nn] = ff\n",
    "  \n",
    "        \n",
    "        \n",
    "      \n",
    "  record['success'] = s\n",
    "  record['fail'] = f\n",
    "  record['success_percent'] = sp  \n",
    "    \n",
    "  nxx = mycol.insert_one(record)\n",
    "    \n",
    "    \n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Logistic Regression\n",
    "\n",
    "\n",
    "import seaborn\n",
    "\n",
    "genes_withlabels = genes\n",
    "genes_withlabels[\"Labels\"]= genes_labels[\"Class\"]\n",
    "#print (genes_withlabels.columns)\n",
    "X = genes_withlabels.ix[:,1:101].values.reshape(-1,100)\n",
    "#X = genes_withlabels[['gene_1','gene_2','gene_3']].values.reshape(-1,3)\n",
    "#print (X)\n",
    "#print (genes_withlabels['Labels'])\n",
    "def regLogistic(XX,yy):\n",
    "    \n",
    "    \n",
    "    ninst = len(yy)\n",
    "  \n",
    "    y=yy[0:ninst-101]\n",
    "    X=XX[0:ninst-101]\n",
    "    X_exp = XX[ninst-100:]\n",
    "    y_exp = yy[ninst-100:]\n",
    "    print (len(X),len(y))\n",
    "    print (len(X_exp),len(y_exp))\n",
    "    print (X_exp.shape,y_exp.shape)\n",
    "#    print (\"X  \",X)\n",
    "#    print (\"y  \",y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "#    print (\"ytrain \",y_train)\n",
    "#    print (\"ytest  \",y_test)\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    X_exp_scaled = X_scaler.transform(X_exp)\n",
    "    classifier = LogisticRegression(verbose=2)\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    print (f\"Params: {classifier.get_params()}\")\n",
    "    yhold = classifier.predict(X_exp_scaled)\n",
    "#    print(y_test)\n",
    "    print(f\"Training {classifier.score(X_train_scaled, y_train)}\")\n",
    "    print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")\n",
    "    nhits=0\n",
    "    nmiss=0\n",
    "    hact = {}\n",
    "    hpre = {}\n",
    "    for nn in range(0,5):\n",
    "        hact[str(nn)] = 0\n",
    "        hpre[str(nn)]=0\n",
    "    for nn in range(0,len(y_exp)):\n",
    "   #     print (\"comp \",nn,X_exp[nn,0],X_exp[nn,1],X_exp_scaled[nn,0],X_exp_scaled[nn,1],y_exp[nn,0],yhold[nn])\n",
    "        ye = str(y_exp[nn,0])\n",
    "        yp = str(yhold[nn])\n",
    "        hact[ye]+=1\n",
    "        hpre[yp]+=1\n",
    "        \n",
    "        if (yhold[nn] == y_exp[nn]):\n",
    "            nhits+=1\n",
    "        else:\n",
    "            nmiss+=1\n",
    "            \n",
    "    print (f\"Hits : {nhits}   Miss : {nmiss}\")\n",
    "#    for nn in range(0,5):\n",
    "#        print (nn,hact[str(nn)],hpre[str(nn)])\n",
    "    return (yhold)\n",
    "\n",
    "#y = genes_labels['Class'].values.reshape(-1,1)\n",
    "\n",
    "hact = {}\n",
    "for val in genes_labels['Class'].values:\n",
    "    if val in hact:\n",
    "        hact[val]+=1\n",
    "    else:\n",
    "        hact[val] = 1\n",
    "        \n",
    "for val in hact:\n",
    "    print (\"HO \",val,hact[val])\n",
    "y = label_encoder.transform(genes_labels['Class'])\n",
    "y = y.reshape(-1,1)\n",
    "#print (y)\n",
    "colors = [\"red\",\"blue\",\"green\",\"brown\",\"purple\"]\n",
    "cols = []\n",
    "for nn in y:\n",
    "    cols.append(colors[nn[0]])\n",
    "    \n",
    "step = 5\n",
    "for nn in range(1,200,step): \n",
    "  print (nn)\n",
    "  X = genes_withlabels.ix[:,nn:nn+step].values.reshape(-1,step)\n",
    "  ypred = regLogistic(X,y)\n",
    "#print (prob) \n",
    "#genes_withlabels['proba'] = prob\n",
    "#print (genes.head())\n",
    "#print (genes_withlabels.columns)\n",
    "#for row in genes_withlabels.iterrows():\n",
    "#  print (row[1]['gene_0'],row[1]['gene_5'],row[1]['Labels'])\n",
    "\n",
    "#plt.scatter(X[:,0],X[:,1],c=cols)\n",
    "#genes.plot.scatter(\"gene_0\",\"gene_1\",c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X = genes[[1,2]].values\n",
    "\n",
    "\n",
    "y = label_encoder.transform(genes_labels['Class'])\n",
    "y = y.reshape(-1,1)\n",
    "print (y.shape)\n",
    "#y_binary = y\n",
    "y_binary = to_categorical(y)\n",
    "print (y_binary.shape)\n",
    "\n",
    "def neuralNetwork(X,y):\n",
    "    nx = X.shape[1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=nx*3, activation='relu', input_dim=nx))\n",
    "    model.add(Dense(units=nx*3, activation='relu', input_dim=nx))\n",
    "    model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print (\"SHps \",X_train_scaled.shape)\n",
    "    print (\"Shps \",y_train.shape)\n",
    "    model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        epochs=40,\n",
    "        shuffle=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    _, train_acc = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "    _, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    return (train_acc,test_acc)\n",
    "    \n",
    "number_columns = genes.shape[0]\n",
    "print (number_columns)\n",
    "\n",
    "genes_withlabels = genes\n",
    "genes_withlabels[\"Labels\"]= genes_labels[\"Class\"]\n",
    "\n",
    "X = genes_withlabels[genes_labels[\"Class\"] == \"PRAD\"].values\n",
    "print (X.shape)\n",
    "\n",
    "for nx in range(1,number_columns,1):    \n",
    "    X = genes.iloc[:,nx:nx+1]\n",
    "    train_acc,test_acc = neuralNetwork(X,y_binary)\n",
    "    print (nx,train_acc,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crime = pd.read_csv(\"data/communities-data.csv\")\n",
    "#print (crime.head())\n",
    "print (crime.columns)\n",
    "columns = crime.columns\n",
    "for col in columns:\n",
    "    df = crime[col]\n",
    "    print (col)\n",
    "    if \"?\" in df.values:\n",
    "        print (\"drop \",col)\n",
    " #       crime.drop(col,inplace=True)\n",
    "        \n",
    "print (crime.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = pd.read_csv(\"data/ENB2012_data.csv\")\n",
    "\n",
    "print (energy.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = energy[['X1','X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8',]].values\n",
    "\n",
    "target = energy['Y1'].values\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)\n",
    "print (\"set up model\")\n",
    "model = SVR(kernel='rbf', C=100, gamma='auto', degree=3, epsilon=.1,\n",
    "               coef0=1)\n",
    "print (\"fit data\")\n",
    "model.fit(data, target)\n",
    "print (\"predict\")\n",
    "model.predict(data)\n",
    "print(\"R2 \",model.sort(data,target))\n",
    "print (\"done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple Linear Regression\n",
    "# X = energy[['X1','X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8',]].values\n",
    "\n",
    "Xs = ['X1','X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8',]\n",
    "ys = ['Y1','Y2']\n",
    "\n",
    "\n",
    "def linearReg(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)\n",
    "\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    y_train_scaled = y_scaler.transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "    model = LinearRegression()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    r2 = r2_score(y_test, predicted)\n",
    "    return r2\n",
    " #   print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "  #  print(f\"R-squared (R2 ): {r2}\")\n",
    "    print(r2,model.score(X_test, y_test))\n",
    "    \n",
    "for yy in ys:\n",
    "    for xx in Xs:\n",
    "      X = energy[xx].values.reshape(-1,1)\n",
    "      y = energy[yy].values.reshape(-1,1)    \n",
    "      r2 = linearReg(X,y)\n",
    "      print (yy,xx,r2)\n",
    "        \n",
    "energy.plot.scatter('X4','Y1')\n",
    "energy.plot.scatter('Y1','Y2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.shape\n",
    "#print (y)\n",
    "yy = [1 if n[0] == 0 else 0 for n in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.017209</td>\n",
       "      <td>3.265527</td>\n",
       "      <td>5.478487</td>\n",
       "      <td>10.431999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.175175</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.926711</td>\n",
       "      <td>8.210257</td>\n",
       "      <td>9.723516</td>\n",
       "      <td>7.220030</td>\n",
       "      <td>9.119813</td>\n",
       "      <td>12.003135</td>\n",
       "      <td>9.650743</td>\n",
       "      <td>8.921326</td>\n",
       "      <td>5.286759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>1.588421</td>\n",
       "      <td>7.586157</td>\n",
       "      <td>9.623011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.816049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.593372</td>\n",
       "      <td>7.323865</td>\n",
       "      <td>9.740931</td>\n",
       "      <td>6.256586</td>\n",
       "      <td>8.381612</td>\n",
       "      <td>12.674552</td>\n",
       "      <td>10.517059</td>\n",
       "      <td>9.397854</td>\n",
       "      <td>2.094168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.511759</td>\n",
       "      <td>4.327199</td>\n",
       "      <td>6.881787</td>\n",
       "      <td>9.870730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.972130</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.125213</td>\n",
       "      <td>8.127123</td>\n",
       "      <td>10.908640</td>\n",
       "      <td>5.401607</td>\n",
       "      <td>9.911597</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>9.788359</td>\n",
       "      <td>10.090470</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.663618</td>\n",
       "      <td>4.507649</td>\n",
       "      <td>6.659068</td>\n",
       "      <td>10.196184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.843375</td>\n",
       "      <td>0.434882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.076566</td>\n",
       "      <td>8.792959</td>\n",
       "      <td>10.141520</td>\n",
       "      <td>8.942805</td>\n",
       "      <td>9.601208</td>\n",
       "      <td>11.392682</td>\n",
       "      <td>9.694814</td>\n",
       "      <td>9.684365</td>\n",
       "      <td>3.292001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.655741</td>\n",
       "      <td>2.821547</td>\n",
       "      <td>6.539454</td>\n",
       "      <td>9.738265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.566967</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.996032</td>\n",
       "      <td>8.891425</td>\n",
       "      <td>10.373790</td>\n",
       "      <td>7.181162</td>\n",
       "      <td>9.846910</td>\n",
       "      <td>11.922439</td>\n",
       "      <td>9.217749</td>\n",
       "      <td>9.461191</td>\n",
       "      <td>5.110372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene_0    gene_1    gene_2    gene_3     gene_4  gene_5    gene_6  \\\n",
       "0     0.0  2.017209  3.265527  5.478487  10.431999     0.0  7.175175   \n",
       "1     0.0  0.592732  1.588421  7.586157   9.623011     0.0  6.816049   \n",
       "2     0.0  3.511759  4.327199  6.881787   9.870730     0.0  6.972130   \n",
       "3     0.0  3.663618  4.507649  6.659068  10.196184     0.0  7.843375   \n",
       "4     0.0  2.655741  2.821547  6.539454   9.738265     0.0  6.566967   \n",
       "\n",
       "     gene_7  gene_8  gene_9  ...  gene_20521  gene_20522  gene_20523  \\\n",
       "0  0.591871     0.0     0.0  ...    4.926711    8.210257    9.723516   \n",
       "1  0.000000     0.0     0.0  ...    4.593372    7.323865    9.740931   \n",
       "2  0.452595     0.0     0.0  ...    5.125213    8.127123   10.908640   \n",
       "3  0.434882     0.0     0.0  ...    6.076566    8.792959   10.141520   \n",
       "4  0.360982     0.0     0.0  ...    5.996032    8.891425   10.373790   \n",
       "\n",
       "   gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
       "0    7.220030    9.119813   12.003135    9.650743    8.921326    5.286759   \n",
       "1    6.256586    8.381612   12.674552   10.517059    9.397854    2.094168   \n",
       "2    5.401607    9.911597    9.045255    9.788359   10.090470    1.683023   \n",
       "3    8.942805    9.601208   11.392682    9.694814    9.684365    3.292001   \n",
       "4    7.181162    9.846910   11.922439    9.217749    9.461191    5.110372   \n",
       "\n",
       "   gene_20530  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 20531 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes.iloc[:, 1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(XX,yy):\n",
    "    ninst = len(yy)\n",
    "    print (XX.shape)\n",
    "    y=yy[0:ninst-101]\n",
    "    X=XX[0:ninst-101]\n",
    "    X_exp = XX[ninst-100:]\n",
    "    y_exp = yy[ninst-100:]\n",
    "    y_exp_hist = {}\n",
    "    for val in y_exp:\n",
    "        if val in y_exp_hist:\n",
    "            y_exp_hist[val]+=1\n",
    "        else:\n",
    "            y_exp_hist[val]=1\n",
    "    for val in y_exp_hist:\n",
    "        print (\"Y EXP \",val,y_exp_hist[val])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=estimators)\n",
    "    parameters = { \n",
    "        'max_features':[5],\n",
    "        'n_estimators':[5,10,50,100],\n",
    "        'min_samples_leaf': [1,5,10,50,100]\n",
    "    }\n",
    "\n",
    "    rfg = GridSearchCV(rf, parameters)\n",
    "    rfg.fit(X_train, y_train)\n",
    "    print (\"Best\")\n",
    "    print (rfg.best_estimator_)\n",
    "    print (rfg.best_score_)\n",
    "    print (rfg.best_params_)\n",
    "    print (rfg.best_index_)\n",
    "    train_score = rfg.score(X_train, y_train)\n",
    "    test_score = rfg.score(X_test, y_test)\n",
    "##    importances = rfg.feature_importances_\n",
    "    #\n",
    " #   y_pred = rfg.predict(XX)\n",
    "    y_pred = rfg.predict(X_exp)\n",
    "##    importances = rfg.feature_importances_\n",
    "    success=0\n",
    "    fail=0 \n",
    "    s = {}\n",
    "    f= {}\n",
    "    for nn in range(0,len(y_pred)):\n",
    "   #     if (y_pred[nn] == yy[nn]):\n",
    "        if (y_pred[nn] == y_exp[nn]):\n",
    "            success+=1\n",
    "            if classes[y_pred[nn]] in s:\n",
    "                s[classes[y_pred[nn]]] +=1\n",
    "            else:\n",
    "                s[classes[y_pred[nn]]] = 1\n",
    "        else:\n",
    "            fail+=1\n",
    "            if classes[y_pred[nn]] in f:\n",
    "                f[classes[y_pred[nn]]] +=1\n",
    "            else:\n",
    "                f[classes[y_pred[nn]]] = 1\n",
    "    \n",
    "    return train_score,test_score,success,fail,s,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2         3          4\n",
      "0   4.203348   0.063642   2.654609  1.340551   0.000059\n",
      "1   4.667388   5.244526  22.266744  6.857168  10.065933\n",
      "2  12.994962   0.573036  24.172190  7.258687  40.603319\n",
      "3   0.062905  15.782105   3.863157  0.240098   0.087354\n",
      "4   1.766820   0.127087   2.447552  0.017996   0.062620\n",
      "prad  2027\n",
      "rand  10 19941\n",
      "801 801\n",
      "(801, 10)\n",
      "Y EXP  0 43\n",
      "Y EXP  3 17\n",
      "Y EXP  2 17\n",
      "Y EXP  4 16\n",
      "Y EXP  1 7\n",
      "Best\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.820952380952381\n",
      "{'max_features': 10, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Science Joe\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 0.8685714285714285,\n",
       " 80,\n",
       " 20,\n",
       " {'BRCA': 34, 'KIRC': 15, 'PRAD': 16, 'LUAD': 11, 'COAD': 4},\n",
       " {'BRCA': 7, 'LUAD': 8, 'KIRC': 5})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import random\n",
    "scores = {}\n",
    "df = pd.DataFrame()    \n",
    "\n",
    "for mm in range(0,5):\n",
    "    X=genes.iloc[:, 1:]\n",
    "    yy = [1 if n[0] == mm else 0 for n in y]\n",
    "    kbestSelector = SelectKBest(chi2, k=10)\n",
    "    kbestSelector.fit(X, yy)\n",
    "    scores[mm] = {}\n",
    "    df[mm] = kbestSelector.scores_\n",
    "    for nn in range(0,len(kbestSelector.scores_)):\n",
    "        scores[mm][nn] = kbestSelector.scores_[nn]\n",
    "\n",
    "    \n",
    "#df1[df1.apply(lambda x: x.between(x.quantile(.25), x.quantile(.75))).all(1)]    \n",
    "print (df.head())\n",
    "\n",
    "for mm in range(0,5):\n",
    "    \n",
    "    ss=sorted(scores[mm].items(), key = \n",
    "             lambda kv:(kv[1], kv[0]),reverse=True)\n",
    "#    print (ss)\n",
    "#  'PRAD' 'LUAD' 'BRCA' 'KIRC' 'COAD'\n",
    "brca = df[0][df[0] > df[0].quantile(.90)]\n",
    "coad = df[1][df[1] > df[1].quantile(.90)]\n",
    "kirc = df[2][df[2] > df[2].quantile(.90)]\n",
    "luad = df[3][df[3] > df[3].quantile(.90)]\n",
    "prad = df[4][df[4] > df[4].quantile(.90)]\n",
    "print (\"prad \",len(prad))\n",
    "rand = random.sample(range(20531), 5)\n",
    "print (\"rand \",len(rand),max(rand))\n",
    "\n",
    "#print (df[2][df[2] > df[2].quantile(.90)])\n",
    "#X = genes.idx[brca.index]\n",
    "#X = genes.ix[:,prad.index].values.reshape(-1,len(prad.index))\n",
    "X = genes.ix[:,rand].values.reshape(-1,len(rand))\n",
    "#yy = [1 if n[0] == 0 else 0 for n in y]\n",
    "yy = [n[0]  for n in y]\n",
    "#yy=y   \n",
    "#print (yy)\n",
    "\n",
    "print (len(yy),len(X))\n",
    "randomForest(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d9b04200f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(kbestSelector.scores_).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
